# -*- coding: utf-8 -*-
"""Layer8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qEOLrVrgpc5HtwwGzyhqC9fY9Y-ossHq

# Layer 8
"""

! pip install shap

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import heapq
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import cross_val_score, RandomizedSearchCV
from sklearn.preprocessing import RobustScaler
from sklearn.utils.class_weight import compute_class_weight
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
import shap
import shap.plots as shap_plots

"""# Reading Data From CSV files"""

train_data = pd.read_csv('./train.csv')
valid_data = pd.read_csv('./valid.csv')
test_data = pd.read_csv('./test.csv')

"""## Extracting X and Y"""

X_train, y_train = train_data.iloc[:, :-4], train_data.iloc[:, -4:]
X_valid, y_valid = valid_data.iloc[:, :-4], valid_data.iloc[:, -4:]
X_test = test_data.iloc[:, 1:]
y_train_arr = [y_train.iloc[:, i] for i in range(4)]
y_valid_arr = [y_valid.iloc[:, i] for i in range(4)]

"""# Data Preprocessing

## Checking for missing values
"""

X_train.isnull().sum().sum()

X_valid.isnull().sum().sum()

X_test.isnull().sum().sum()

y_train.isnull().sum()

y_valid.isnull().sum()

len(y_train)

"""Therefore y_train and y_valid label 2 only have missing values"""

print(f"Missing values percentage of train label 2 column : {y_train_arr[1].isnull().sum()*100/len(y_train)}%")
print(f"Missing values percentage of valid label 2 column : {y_valid_arr[1].isnull().sum()*100/len(y_valid)}%")

"""Since the missing values percentage of train data label 2 column and valid data label 2 column are low, missing values are deleted"""

train_data_missing_removed = train_data.dropna()
valid_data_missing_removed = valid_data.dropna()
train_data_missing_removed.reset_index(drop=True, inplace=True)
valid_data_missing_removed.reset_index(drop=True, inplace=True)
X_train, y_train = train_data.iloc[:, :-4], train_data.iloc[:, -4:]
X_valid, y_valid = valid_data.iloc[:, :-4], valid_data.iloc[:, -4:]
X_train_missing_removed, y_train_missing_removed = train_data_missing_removed.iloc[:, :-4], train_data_missing_removed.iloc[:, -4:]
X_valid_missing_removed, y_valid_missing_removed = valid_data_missing_removed.iloc[:, :-4], valid_data_missing_removed.iloc[:, -4:]
X_train_arr = [X_train, X_train_missing_removed, X_train, X_train]
X_valid_arr = [X_valid, X_valid_missing_removed, X_valid, X_valid]
X_test_arr = [X_test, X_test, X_test, X_test]

y_train_arr = [y_train.iloc[:, 0], y_train_missing_removed.iloc[:, 1], y_train.iloc[:, 2], y_train.iloc[:, 3]]
y_valid_arr = [y_valid.iloc[:, 0], y_valid_missing_removed.iloc[:, 1], y_valid.iloc[:, 2], y_valid.iloc[:, 3]]

"""## Scaling

"RobustScaler" standardizes the data, first using training data to calculate scaling parameters and then applying the same transformation to validation and test datasets for consistent scaling in machine learning modeling.
"""

scaler = RobustScaler()
for i in range(4):
  X_train_arr[i] = pd.DataFrame(data=scaler.fit_transform(X_train_arr[i]), columns=X_train_arr[i].columns)
  X_valid_arr[i] = pd.DataFrame(data=scaler.transform(X_valid_arr[i]), columns=X_valid_arr[i].columns)
  X_test_arr[i] = pd.DataFrame(data=scaler.transform(X_test_arr[i]), columns=X_test_arr[i].columns)

"""# Data Visualization"""

def visualize_label(y, title, x_title, y_title='Number of rows'):
  unique_classes, class_counts = np.unique(y, return_counts=True)
  plt.bar(unique_classes, class_counts)
  plt.xlabel(x_title)
  plt.ylabel(y_title)
  plt.title(title)
  plt.show()

visualize_label(y_train_arr[0], "Number of rows versus Speaker ID","Speaker ID");
visualize_label(y_train_arr[1], "Number of rows versus Age","Age");
visualize_label(y_train_arr[2], "Number of rows versus Gender","Gender");
visualize_label(y_train_arr[3], "Number of rows versus Accent","Accent");

"""The classes of label 1 are approximately uniformly balanced. In other 3 labes classes are inbalanced. To handle this, class weights are assigned in a latter stage

# Feature Reduction

Principal Component Analysis (PCA) is a tool used to simplify data by reducing its complexity and selecting the most important features. In this context, it's being used to make the features simpler.
"""

def pca_reduce(X,pca, first_fit=False):
  if first_fit:
    X_pca = pca.fit_transform(X)
  else:
    X_pca = pca.transform(X)
  return pd.DataFrame(data=X_pca, columns=[X.columns[i] for i in range(X_pca.shape[1])])

desired_variance_ratio = 0.95
pca = PCA(n_components=desired_variance_ratio, svd_solver='full')
X_train_after_reduction_arr = []
X_valid_after_reduction_arr= []
X_test_after_reduction_arr = []
for i in range(4):
  X_train_after_reduction_arr.append(pca_reduce(X_train_arr[i] ,pca, first_fit=True))
  X_valid_after_reduction_arr.append(pca_reduce(X_valid_arr[i] ,pca))
  X_test_after_reduction_arr.append(pca_reduce(X_test_arr[i] ,pca))

"""## Useful Functions"""

def predict(X, model):
  y_pred = model.predict(X)
  return pd.Series(y_pred)

def find_accuracy(y_predicted, y_correct):
  accuracy = accuracy_score(y_predicted, y_correct)
  return accuracy

"""# Creating models and predicting

Random Forest, kNN and SVC models were considered. After conducting several executions and comparing accuracies SVC models were selected over other two models.

## Random Forest

andom Forest is a practical machine learning approach frequently chosen for its straightforwardness and efficiency in addressing classification tasks.

### Model creating
"""

def random_forest(X, y, n_estimators=100, random_state=42):
    class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)
    class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}
    model = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state, class_weight=class_weight_dict)
    model.fit(X, y)
    return model

random_forest_model_arr = []
for i in range(4):
  random_forest_model_arr.append(random_forest(X_train_after_reduction_arr[i], y_train_arr[i]))

"""### Predicting for Valid data"""

y_pred_for_valid_arr = [predict(X_valid_after_reduction_arr[i], random_forest_model_arr[i]) for i in range(4)]
accuracy_for_valid_data_arr = [find_accuracy(y_pred_for_valid_arr[i], y_valid_arr[i]) for i in range(4)]
for i in range(4):
  print(f"Accuracy score for label {i+1} : {accuracy_for_valid_data_arr[i]}")

"""## kNN

k-Nearest Neighbors (kNN) is a useful machine learning method often selected for its simplicity and effectiveness in handling classification tasks.

### Model creating
"""

def knn(X, y, n_neighbors=5):
    class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)
    class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}
    model = KNeighborsClassifier(n_neighbors=n_neighbors, weights='uniform')
    model.fit(X, y)
    return model

knn_model_arr = []
for i in range(4):
  knn_model_arr.append(knn(X_train_after_reduction_arr[i], y_train_arr[i]))

"""### Predicting for Valid data"""

y_pred_for_valid_arr = [predict(X_valid_after_reduction_arr[i], knn_model_arr[i]) for i in range(4)]
accuracy_for_valid_data_arr = [find_accuracy(y_pred_for_valid_arr[i], y_valid_arr[i]) for i in range(4)]
for i in range(4):
  print(f"Accuracy score for label {i+1} : {accuracy_for_valid_data_arr[i]}")

"""## SVC

Support Vector Classification (SVC) is a machine learning technique used in modeling. It is chosen for its effectiveness in solving classification problems.

### Hyperparameter tuning

The SVM model is tuned using a randomized search approach. Hyperparameter values for 'C', 'gamma', 'kernel' , and 'degree' are explored. RandomizedSearchCV with 100 iterations, 5-fold cross-validation, and parallel processing is applied to find the best combination of hyperparameters for the SVM model.
"""

C = [0.1, 1, 10, 100]
gamma = ['scale', 'auto', 0.001, 0.01, 0.1, 1.0]
kernel = ['linear', 'rbf', 'poly']
degree = [2, 3, 4]
svc_tuning_model = SVC()
param_grid = {
    'C': C,
    'gamma': gamma,
    'kernel': kernel,
    'degree': degree,
}
random_search = RandomizedSearchCV(
    svc_tuning_model,
    param_distributions=param_grid,
    n_iter=100,
    cv=5,
    n_jobs=-1,
    verbose=1,
    random_state=40
)
for i in range(4):
  random_search.fit(X_train_after_reduction_arr[i], y_train_arr[i])
  print(random_search.best_params)

"""### Model creating

class weights are applied to address the issue of imbalanced classes, ensuring that the model effectively learns from all classes in the dataset.
"""

def svm(X, y):
  class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)
  class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}
  model = SVC(kernel='rbf', random_state=40, class_weight=class_weight_dict, C=100)
  model.fit(X, y)
  return model

def svm_linear(X, y):
  class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)
  class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}
  model = SVC(kernel='linear', random_state=40, class_weight=class_weight_dict)
  model.fit(X, y)
  return model

svm_model_arr = []
for i in range(4):
  svm_model_arr.append(svm(X_train_after_reduction_arr[i], y_train_arr[i]))

"""### Predicting for Valid data"""

y_pred_for_valid_arr = [predict(X_valid_after_reduction_arr[i], svm_model_arr[i]) for i in range(4)]
accuracy_for_valid_data_arr = [find_accuracy(y_pred_for_valid_arr[i], y_valid_arr[i]) for i in range(4)]
for i in range(4):
  print(f"Accuracy score for label {i+1} : {accuracy_for_valid_data_arr[i]}")

"""# Evaluating

## Cross Validation

This computes and displays the cross-validation scores for each of the four SVM models for their respective labels.
"""

for i in range(4):
  scores = cross_val_score(svm_model_arr[i],X_train_after_reduction_arr[i], y_train_arr[i], cv=5)
  print(f"Cross validations scores for label {i} : {scores}")

"""## Heat Maps of the Confusion Matrixes

This creates a heatmap representation of a confusion matrix. Then, it calculates and visualizes confusion matrices for different labels: "Speaker ID," "Age," "Gender," and "Accent."
"""

def visualize_confusion(confusion, title):
  plt.figure(figsize=(20, 10))
  sns.heatmap(confusion, annot=True, fmt="d", cmap="Blues", cbar=False)
  plt.xlabel("Predicted")
  plt.ylabel("Actual")
  plt.title(f"Confusion Matrix for {title}")
  plt.show()

confusion_arr = [confusion_matrix(y_valid_arr[i], y_pred_for_valid_arr[i]) for i in range(4)]

visualize_confusion(confusion_arr[0], "Speaker ID")
visualize_confusion(confusion_arr[1], "Age")
visualize_confusion(confusion_arr[2], "Gender")
visualize_confusion(confusion_arr[3], "Accent")

"""## Classification Reports

The predictions are generated for validation data using SVM models for four different labels. Then it computes and prints the classification report, including metrics like precision, recall, and F1-score, for each label.
"""

y_pred_for_X_valid_arr = []
accuracy_for_valid_data_arr = []
for i in range(4):
  y_pred_for_X_valid_arr.append(predict(X_valid_after_reduction_arr[i], svm_model_arr[i]))
  accuracy_for_valid_data_arr.append(find_accuracy(y_pred_for_X_valid_arr[i], y_valid_arr[i]))
  print(f"Classification Report for Label {i+1}")
  print(classification_report(y_valid_arr[i], y_pred_for_X_valid_arr[i]))
  print()

"""## Accuracies for valid data"""

for i in range(4):
  print(f"Label {i+1} accuracy for valid data : {accuracy_for_valid_data_arr[i]}")

"""# Explainability (Interpreting the label predictions and any cross-relations with labels)

Explaning rbf kernel SVM models are complex. Therefore, to describe the explainability, the linear kernel SVC models are used.
"""

svm_linear_model_arr = [svm_linear(X_train_after_reduction_arr[i], y_train_arr[i]) for i in range(4)]

"""## SHAP

SHAP is a framework and a set of techniques used in machine learning to explain the predictions made by complex models, such as SVM.
"""

for i in range(4):
  explainer = shap.Explainer(svm_linear_model_arr[i], X_train_after_reduction_arr[i])
  instance_index = 0
  shap_values = explainer.shap_values(X_test_after_reduction_arr[i])
  shap.summary_plot(shap_values, X_test_after_reduction_arr[i])
  shap.summary_plot(shap_values)

"""However, due to the high RAM usage of shap.summary_plot and to the complexity, using SHAP was not very effective.

## Using weights assigned to the features

SVC.coef_ are weights assigned to the features when kernel="linear".
"""

def print_top_weight_features(svm_model, n_classes):
  coefficients = svm_model.coef_
  top_weights = []
  for class_A in range(n_classes):
    for class_B in range(class_A + 1, n_classes):
        index = int(class_A * (2 * n_classes - class_A - 1) / 2 + class_B - class_A - 1)
        for feature_index, weight in enumerate(coefficients[index]):
            absolute_weight = np.abs(weight)
            if len(top_weights) < 20:
                heapq.heappush(top_weights, (absolute_weight, feature_index, class_A, class_B, weight))
            else:
                if absolute_weight > top_weights[0][0]:
                    heapq.heappop(top_weights)
                    heapq.heappush(top_weights, (absolute_weight, feature_index, class_A, class_B, weight))
  values_to_print = []
  for i in range(20):
    values_to_print.insert(0, heapq.heappop(top_weights))
  i = 0
  for (absolute_weight, feature_index, class_A, class_B, weight) in values_to_print:
    print(f"Top {i + 1}: The weight assigned to feature {feature_index} between class {class_A} and class {class_B} is {weight}")
    i+=1

for i in range(4):
  print(f"\nFor the Class label {i+1}")
  print_top_weight_features(svm_linear_model_arr[i], len(y_train_arr[i].unique()))

"""According to the above outputs, for the label 1, features 97, 121, 37, 42 and 144 affects more than other features. For the label 2, features 59, 146, 20, 92 and 119 affects more than other features. For the label 3, features 9, 16, 124, 54 and 27 affects more than other features. For the label 4, features 62, 134, 144, 36 and 62 affects more than other features.

## Using constants in the decision function

SVC.intercept_ are constants in decision function.
"""

def print_top_constants(svm_model, n_classes, binary=False):
  intercept = svm_model.intercept_
  top_constants = []
  for class_A in range(n_classes):
    for class_B in range(class_A + 1, n_classes):
        index = int(class_A * (2 * n_classes - class_A - 1) / 2 + class_B - class_A - 1)
        intercept_value = intercept[index]
        absolute_intercept_value = np.abs(intercept[index])
        if len(top_constants) < 20:
            heapq.heappush(top_constants, (absolute_intercept_value, intercept_value, class_A, class_B))
        else:
            if absolute_intercept_value > top_constants[0][0]:
                heapq.heappop(top_constants)
                heapq.heappush(top_constants, (absolute_intercept_value, intercept_value, class_A, class_B))
  values_to_print = []
  if binary:
     values_to_print.append(top_constants[0])
  else:
    for i in range(20):
      values_to_print.insert(0, heapq.heappop(top_constants))
  i = 0
  for (absolute_intercept_value, intercept_value, class_A, class_B) in values_to_print:
    print(f"Top {i + 1}: Intercept/Constant in the decision function is {intercept_value} between the classes {class_A} and {class_B}")
    i+=1

for i in range(4):
  print(f"\nFor the Class Label {i+1}")
  binary = False
  if i==2:
    binary=True
  print_top_constants(svm_linear_model_arr[i], len(y_train_arr[i].unique()), binary=binary)

"""# Predicting for test data"""

y_pred_for_X_test_arr = []
for i in range(4):
  y_pred_for_X_test_arr.append(predict(X_test_after_reduction_arr[i], svm_model_arr[i]))

"""# Creating the solutions csv"""

def createCSVOutput(y_arr, filename):
  data = {
    'ID' : list(range(1, y_arr[0].shape[0] + 1)),
    'label_1': y_arr[0],
    'label_2': y_arr[1],
    'label_3': y_arr[2],
    'label_4': y_arr[3]
  }
  df = pd.DataFrame(data)
  df.to_csv(filename, index=False)

createCSVOutput(y_pred_for_X_test_arr, './output.csv')







